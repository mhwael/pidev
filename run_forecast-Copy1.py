{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "afb545e4-8a7b-453f-b195-68a49ace0b7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.13.5 | packaged by Anaconda, Inc. | (main, Jun 12 2025, 16:37:03) [MSC v.1929 64 bit (AMD64)]\n",
      "All imports OK ✅\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(\"Python:\", sys.version)\n",
    "\n",
    "import pandas, numpy, sklearn, sqlalchemy, pymysql\n",
    "print(\"All imports OK ✅\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c531d58-a587-4341-be1f-d02d5fe66bec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ok</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ok\n",
       "0   1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "engine = create_engine(\"mysql+pymysql://root:@127.0.0.1:3306/esports_db?charset=utf8mb4\")\n",
    "\n",
    "# quick test\n",
    "df_test = pd.read_sql(\"SELECT 1 AS ok\", engine)\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa26e405-baa2-4779-90f2-6cabf8b3697b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tables_in_esports_db</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>doctrine_migration_versions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>game</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>guide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>guide_rating</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>guide_step</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>messages_forum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>messenger_messages</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>order</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>order_item</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>order_product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>product_forecast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>sujets_forum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>team</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>team_members</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>tournament</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>tournament_teams</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>user</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Tables_in_esports_db\n",
       "0   doctrine_migration_versions\n",
       "1                          game\n",
       "2                         guide\n",
       "3                  guide_rating\n",
       "4                    guide_step\n",
       "5                messages_forum\n",
       "6            messenger_messages\n",
       "7                         order\n",
       "8                    order_item\n",
       "9                 order_product\n",
       "10                      product\n",
       "11             product_forecast\n",
       "12                 sujets_forum\n",
       "13                         team\n",
       "14                 team_members\n",
       "15                   tournament\n",
       "16             tournament_teams\n",
       "17                         user"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tables = pd.read_sql(\"SHOW TABLES\", engine)\n",
    "tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "857e43ff-aaf0-45d1-b048-bb136db9d051",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>products</th>\n",
       "      <th>orders</th>\n",
       "      <th>order_items</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16</td>\n",
       "      <td>37</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   products  orders  order_items\n",
       "0        16      37           12"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "counts = pd.read_sql(\"\"\"\n",
    "SELECT\n",
    "  (SELECT COUNT(*) FROM product) AS products,\n",
    "  (SELECT COUNT(*) FROM `order`) AS orders,\n",
    "  (SELECT COUNT(*) FROM order_item) AS order_items\n",
    "\"\"\", engine)\n",
    "\n",
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "362e2afa-4b3d-478d-9be8-98b087e0e280",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserted orders: 1200\n",
      "Inserted order_items: 2399\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from sqlalchemy import text\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "# --- settings ---\n",
    "N_ORDERS = 1200\n",
    "DAYS_BACK = 365\n",
    "\n",
    "STATUSES = [\"PAID\", \"DELIVERED\", \"CANCELLED\"]\n",
    "STATUS_WEIGHTS = [0.72, 0.18, 0.10]\n",
    "\n",
    "PAY_METHODS = [\"CARD\", \"COD\"]\n",
    "PAY_METHOD_WEIGHTS = [0.70, 0.30]\n",
    "\n",
    "FIRST_NAMES = [\"Seif\", \"Ahmed\", \"Yasmine\", \"Sarra\", \"Mohamed\", \"Rayen\", \"Aya\", \"Amine\", \"Mariem\", \"Anis\", \"Ons\", \"Fares\"]\n",
    "LAST_NAMES  = [\"Amri\", \"Ben Ali\", \"Trabelsi\", \"Jlassi\", \"Gharbi\", \"Haddad\", \"Bouslama\", \"Mhiri\", \"Cherif\", \"Khalfallah\", \"Sassi\", \"Mansouri\"]\n",
    "\n",
    "def rand_date_within(days_back: int) -> datetime:\n",
    "    now = datetime.now()\n",
    "    delta_days = random.randint(0, days_back)\n",
    "    delta_secs = random.randint(0, 86400-1)\n",
    "    return now - timedelta(days=delta_days, seconds=delta_secs)\n",
    "\n",
    "# Load products\n",
    "products = pd.read_sql(\"SELECT id, price FROM product\", engine)\n",
    "assert len(products) > 0, \"No products found in product table.\"\n",
    "\n",
    "product_ids = products[\"id\"].tolist()\n",
    "price_map = dict(zip(products[\"id\"], products[\"price\"].astype(float)))\n",
    "\n",
    "def pick_items():\n",
    "    # 1-5 different products\n",
    "    k = random.choices([1,2,3,4,5], weights=[0.45,0.25,0.17,0.10,0.03])[0]\n",
    "    chosen = random.sample(product_ids, k=min(k, len(product_ids)))\n",
    "    items = []\n",
    "    for pid in chosen:\n",
    "        qty = random.choices([1,2,3,4,5,6], weights=[0.62,0.20,0.10,0.05,0.02,0.01])[0]\n",
    "        items.append((pid, qty))\n",
    "    return items\n",
    "\n",
    "def compute_total(items):\n",
    "    total = 0.0\n",
    "    for pid, qty in items:\n",
    "        total += float(price_map[pid]) * int(qty)\n",
    "    return round(total, 2)\n",
    "\n",
    "with engine.begin() as conn:\n",
    "    inserted_orders = 0\n",
    "    inserted_items = 0\n",
    "\n",
    "    for _ in range(N_ORDERS):\n",
    "        created_at = rand_date_within(DAYS_BACK)\n",
    "        status = random.choices(STATUSES, weights=STATUS_WEIGHTS)[0]\n",
    "        payment_method = random.choices(PAY_METHODS, weights=PAY_METHOD_WEIGHTS)[0]\n",
    "\n",
    "        payment_status = \"PAID\" if status in (\"PAID\", \"DELIVERED\") else \"CANCELLED\"\n",
    "\n",
    "        first = random.choice(FIRST_NAMES)\n",
    "        last = random.choice(LAST_NAMES)\n",
    "        phone = str(random.randint(20000000, 99999999))\n",
    "        email = f\"{first.lower()}.{last.lower().replace(' ','')}{random.randint(1,999)}@example.com\"\n",
    "\n",
    "        items = pick_items()\n",
    "        total = compute_total(items)\n",
    "\n",
    "        reference = \"SYN-\" + created_at.strftime(\"%Y%m%d%H%M%S\") + f\"-{random.randint(100,999)}\"\n",
    "\n",
    "        res = conn.execute(text(\"\"\"\n",
    "            INSERT INTO `order`\n",
    "            (reference, total_amount, status, created_at,\n",
    "             customer_first_name, customer_last_name, customer_email, customer_phone,\n",
    "             payment_method, payment_status)\n",
    "            VALUES\n",
    "            (:ref, :total, :status, :created_at,\n",
    "             :fn, :ln, :email, :phone,\n",
    "             :pm, :ps)\n",
    "        \"\"\"), {\n",
    "            \"ref\": reference,\n",
    "            \"total\": f\"{total:.2f}\",\n",
    "            \"status\": status,\n",
    "            \"created_at\": created_at.strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "            \"fn\": first,\n",
    "            \"ln\": last,\n",
    "            \"email\": email,\n",
    "            \"phone\": phone,\n",
    "            \"pm\": payment_method,\n",
    "            \"ps\": payment_status\n",
    "        })\n",
    "        order_id = res.lastrowid\n",
    "        inserted_orders += 1\n",
    "\n",
    "        for pid, qty in items:\n",
    "            unit_price = float(price_map[pid])\n",
    "            conn.execute(text(\"\"\"\n",
    "                INSERT INTO order_item (quantity, unit_price, order_ref_id, product_id)\n",
    "                VALUES (:qty, :unit_price, :order_id, :pid)\n",
    "            \"\"\"), {\n",
    "                \"qty\": int(qty),\n",
    "                \"unit_price\": f\"{unit_price:.2f}\",\n",
    "                \"order_id\": int(order_id),\n",
    "                \"pid\": int(pid)\n",
    "            })\n",
    "            inserted_items += 1\n",
    "\n",
    "    print(\"Inserted orders:\", inserted_orders)\n",
    "    print(\"Inserted order_items:\", inserted_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e78bacc-d2c3-4c2c-a3c0-70dae74568d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>products</th>\n",
       "      <th>orders</th>\n",
       "      <th>order_items</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16</td>\n",
       "      <td>1237</td>\n",
       "      <td>2411</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   products  orders  order_items\n",
       "0        16    1237         2411"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_sql(\"\"\"\n",
    "SELECT\n",
    "  (SELECT COUNT(*) FROM product) AS products,\n",
    "  (SELECT COUNT(*) FROM `order`) AS orders,\n",
    "  (SELECT COUNT(*) FROM order_item) AS order_items\n",
    "\"\"\", engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3118e909-d7a7-4273-b606-9e529728cb92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rows: (1826, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>day</th>\n",
       "      <th>qty_sold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>2025-02-21</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>2025-02-21</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>2025-02-21</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13</td>\n",
       "      <td>2025-02-22</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2025-02-22</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   product_id         day  qty_sold\n",
       "0           7  2025-02-21       1.0\n",
       "1          20  2025-02-21       1.0\n",
       "2           5  2025-02-21       1.0\n",
       "3          13  2025-02-22       1.0\n",
       "4           4  2025-02-22       2.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "sales_q = \"\"\"\n",
    "SELECT\n",
    "  oi.product_id,\n",
    "  DATE(o.created_at) AS day,\n",
    "  SUM(oi.quantity) AS qty_sold\n",
    "FROM order_item oi\n",
    "JOIN `order` o ON o.id = oi.order_ref_id\n",
    "WHERE o.status IN ('PAID','DELIVERED')\n",
    "GROUP BY oi.product_id, DATE(o.created_at)\n",
    "ORDER BY day ASC;\n",
    "\"\"\"\n",
    "sales = pd.read_sql(sales_q, engine)\n",
    "\n",
    "print(\"rows:\", sales.shape)\n",
    "sales.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5fd4e4b6-f4b8-4c91-b0d5-aa585574fd18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.9457165169932266\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Ensure types\n",
    "sales[\"day\"] = pd.to_datetime(sales[\"day\"])\n",
    "sales[\"qty_sold\"] = sales[\"qty_sold\"].astype(float)\n",
    "\n",
    "# Build full date range per product (fill missing days with 0)\n",
    "all_rows = []\n",
    "for pid, g in sales.groupby(\"product_id\"):\n",
    "    g = g.sort_values(\"day\").set_index(\"day\")\n",
    "    idx = pd.date_range(g.index.min(), g.index.max(), freq=\"D\")\n",
    "    g = g.reindex(idx, fill_value=0.0).rename_axis(\"day\").reset_index()\n",
    "    g[\"product_id\"] = pid\n",
    "    all_rows.append(g)\n",
    "\n",
    "df = pd.concat(all_rows, ignore_index=True)\n",
    "\n",
    "# Time features\n",
    "df[\"dow\"] = df[\"day\"].dt.dayofweek\n",
    "df[\"month\"] = df[\"day\"].dt.month\n",
    "\n",
    "# Lag features\n",
    "df[\"lag_1\"]  = df.groupby(\"product_id\")[\"qty_sold\"].shift(1)\n",
    "df[\"lag_7\"]  = df.groupby(\"product_id\")[\"qty_sold\"].shift(7)\n",
    "df[\"lag_14\"] = df.groupby(\"product_id\")[\"qty_sold\"].shift(14)\n",
    "\n",
    "# Rolling means (based on past days)\n",
    "df[\"roll_7\"]  = df.groupby(\"product_id\")[\"qty_sold\"].shift(1).rolling(7).mean().reset_index(level=0, drop=True)\n",
    "df[\"roll_14\"] = df.groupby(\"product_id\")[\"qty_sold\"].shift(1).rolling(14).mean().reset_index(level=0, drop=True)\n",
    "\n",
    "# Fill NaNs\n",
    "df[[\"lag_1\",\"lag_7\",\"lag_14\",\"roll_7\",\"roll_14\"]] = df[[\"lag_1\",\"lag_7\",\"lag_14\",\"roll_7\",\"roll_14\"]].fillna(0.0)\n",
    "\n",
    "features = [\"product_id\",\"dow\",\"month\",\"lag_1\",\"lag_7\",\"lag_14\",\"roll_7\",\"roll_14\"]\n",
    "X = df[features]\n",
    "y = df[\"qty_sold\"]\n",
    "\n",
    "# Train/valid split (time-aware simple split: last 20% as test)\n",
    "cut = int(len(df) * 0.8)\n",
    "X_train, X_test = X.iloc[:cut], X.iloc[cut:]\n",
    "y_train, y_test = y.iloc[:cut], y.iloc[cut:]\n",
    "\n",
    "model = RandomForestRegressor(\n",
    "    n_estimators=250,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    max_depth=12,\n",
    "    min_samples_leaf=2\n",
    ")\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "pred = model.predict(X_test)\n",
    "mae = mean_absolute_error(y_test, pred)\n",
    "print(\"MAE:\", mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "30f9e479-fb93-4bba-a26c-e830c0750b58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(   product_id  forecast_days  predicted_qty  recommended_reorder_qty\n",
       " 0           2              7           4.49                        0\n",
       " 1           4              7           4.40                        6\n",
       " 2           5              7           6.47                        0\n",
       " 3           6              7           4.26                        0\n",
       " 4           7              7           5.78                        0,\n",
       " (16, 4))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import timedelta\n",
    "from sqlalchemy import text\n",
    "\n",
    "# Load current stock\n",
    "prod_df = pd.read_sql(\"SELECT id, stock FROM product\", engine)\n",
    "stock_map = dict(zip(prod_df[\"id\"], prod_df[\"stock\"].fillna(0).astype(int)))\n",
    "\n",
    "forecast_days = 7\n",
    "\n",
    "# We'll start from last available day per product in df\n",
    "results = []\n",
    "\n",
    "for pid, g in df.groupby(\"product_id\"):\n",
    "    g = g.sort_values(\"day\").copy()\n",
    "    last_day = g[\"day\"].max()\n",
    "\n",
    "    # Take last known values to roll forward\n",
    "    hist = g.copy()\n",
    "\n",
    "    future_rows = []\n",
    "    for step in range(1, forecast_days + 1):\n",
    "        d = last_day + timedelta(days=step)\n",
    "\n",
    "        # Build feature row using latest hist\n",
    "        # qty_sold in future unknown -> we use predicted values by updating hist each step\n",
    "        tmp = hist.sort_values(\"day\").copy()\n",
    "\n",
    "        # get lags from hist (last day is last known/predicted)\n",
    "        def get_lag(k):\n",
    "            if len(tmp) >= k:\n",
    "                return float(tmp.iloc[-k][\"qty_sold\"])\n",
    "            return 0.0\n",
    "\n",
    "        lag_1  = get_lag(1)\n",
    "        lag_7  = get_lag(7)\n",
    "        lag_14 = get_lag(14)\n",
    "\n",
    "        # rolling means on previous values\n",
    "        roll_7  = float(tmp[\"qty_sold\"].tail(7).mean()) if len(tmp) >= 1 else 0.0\n",
    "        roll_14 = float(tmp[\"qty_sold\"].tail(14).mean()) if len(tmp) >= 1 else 0.0\n",
    "\n",
    "        row = {\n",
    "            \"product_id\": pid,\n",
    "            \"dow\": d.dayofweek,\n",
    "            \"month\": d.month,\n",
    "            \"lag_1\": lag_1,\n",
    "            \"lag_7\": lag_7,\n",
    "            \"lag_14\": lag_14,\n",
    "            \"roll_7\": roll_7,\n",
    "            \"roll_14\": roll_14,\n",
    "        }\n",
    "\n",
    "        yhat = float(model.predict(pd.DataFrame([row]))[0])\n",
    "        yhat = max(0.0, yhat)  # no negative sales\n",
    "\n",
    "        # append predicted day into hist to feed next step\n",
    "        hist = pd.concat([hist, pd.DataFrame([{\"day\": d, \"product_id\": pid, \"qty_sold\": yhat,\n",
    "                                              \"dow\": row[\"dow\"], \"month\": row[\"month\"],\n",
    "                                              \"lag_1\": row[\"lag_1\"], \"lag_7\": row[\"lag_7\"], \"lag_14\": row[\"lag_14\"],\n",
    "                                              \"roll_7\": row[\"roll_7\"], \"roll_14\": row[\"roll_14\"]}])],\n",
    "                         ignore_index=True)\n",
    "\n",
    "        future_rows.append({\"day\": d.date(), \"pred_qty\": yhat})\n",
    "\n",
    "    pred_total = sum(r[\"pred_qty\"] for r in future_rows)\n",
    "    stock = int(stock_map.get(pid, 0))\n",
    "    safety = 0.20 * pred_total\n",
    "    reorder = int(np.ceil(max(0.0, (pred_total + safety) - stock)))\n",
    "\n",
    "    results.append({\n",
    "        \"product_id\": int(pid),\n",
    "        \"forecast_days\": int(forecast_days),\n",
    "        \"predicted_qty\": float(round(pred_total, 2)),\n",
    "        \"recommended_reorder_qty\": int(reorder),\n",
    "    })\n",
    "\n",
    "forecast_df = pd.DataFrame(results)\n",
    "forecast_df.head(), forecast_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a39a782d-fa50-46c8-aae0-9fab6975cbb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved forecasts: 16\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from sqlalchemy import text\n",
    "\n",
    "now_str = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "with engine.begin() as conn:\n",
    "    for r in forecast_df.to_dict(\"records\"):\n",
    "        conn.execute(text(\"\"\"\n",
    "            INSERT INTO product_forecast (product_id, forecast_days, predicted_qty, recommended_reorder_qty, generated_at)\n",
    "            VALUES (:pid, :days, :pred, :reorder, :gen)\n",
    "            ON DUPLICATE KEY UPDATE\n",
    "              predicted_qty = VALUES(predicted_qty),\n",
    "              recommended_reorder_qty = VALUES(recommended_reorder_qty),\n",
    "              generated_at = VALUES(generated_at)\n",
    "        \"\"\"), {\n",
    "            \"pid\": r[\"product_id\"],\n",
    "            \"days\": r[\"forecast_days\"],\n",
    "            \"pred\": r[\"predicted_qty\"],\n",
    "            \"reorder\": r[\"recommended_reorder_qty\"],\n",
    "            \"gen\": now_str\n",
    "        })\n",
    "\n",
    "print(\"Saved forecasts:\", len(forecast_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9253e003-2d11-4db5-9111-034336582b86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>forecast_days</th>\n",
       "      <th>predicted_qty</th>\n",
       "      <th>recommended_reorder_qty</th>\n",
       "      <th>generated_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16</td>\n",
       "      <td>20</td>\n",
       "      <td>7</td>\n",
       "      <td>7.20</td>\n",
       "      <td>8</td>\n",
       "      <td>2026-02-22 00:29:54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>6.59</td>\n",
       "      <td>0</td>\n",
       "      <td>2026-02-22 00:29:54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>6.52</td>\n",
       "      <td>0</td>\n",
       "      <td>2026-02-22 00:29:54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>6.47</td>\n",
       "      <td>0</td>\n",
       "      <td>2026-02-22 00:29:54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15</td>\n",
       "      <td>19</td>\n",
       "      <td>7</td>\n",
       "      <td>6.42</td>\n",
       "      <td>0</td>\n",
       "      <td>2026-02-22 00:29:54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>5.78</td>\n",
       "      <td>0</td>\n",
       "      <td>2026-02-22 00:29:54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>5.21</td>\n",
       "      <td>0</td>\n",
       "      <td>2026-02-22 00:29:54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>13</td>\n",
       "      <td>17</td>\n",
       "      <td>7</td>\n",
       "      <td>4.85</td>\n",
       "      <td>0</td>\n",
       "      <td>2026-02-22 00:29:54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>14</td>\n",
       "      <td>18</td>\n",
       "      <td>7</td>\n",
       "      <td>4.78</td>\n",
       "      <td>1</td>\n",
       "      <td>2026-02-22 00:29:54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>12</td>\n",
       "      <td>16</td>\n",
       "      <td>7</td>\n",
       "      <td>4.76</td>\n",
       "      <td>5</td>\n",
       "      <td>2026-02-22 00:29:54</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  product_id  forecast_days  predicted_qty  recommended_reorder_qty  \\\n",
       "0  16          20              7           7.20                        8   \n",
       "1   8          12              7           6.59                        0   \n",
       "2   7          11              7           6.52                        0   \n",
       "3   3           5              7           6.47                        0   \n",
       "4  15          19              7           6.42                        0   \n",
       "5   5           7              7           5.78                        0   \n",
       "6   6          10              7           5.21                        0   \n",
       "7  13          17              7           4.85                        0   \n",
       "8  14          18              7           4.78                        1   \n",
       "9  12          16              7           4.76                        5   \n",
       "\n",
       "         generated_at  \n",
       "0 2026-02-22 00:29:54  \n",
       "1 2026-02-22 00:29:54  \n",
       "2 2026-02-22 00:29:54  \n",
       "3 2026-02-22 00:29:54  \n",
       "4 2026-02-22 00:29:54  \n",
       "5 2026-02-22 00:29:54  \n",
       "6 2026-02-22 00:29:54  \n",
       "7 2026-02-22 00:29:54  \n",
       "8 2026-02-22 00:29:54  \n",
       "9 2026-02-22 00:29:54  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_sql(\"SELECT * FROM product_forecast ORDER BY predicted_qty DESC LIMIT 10\", engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "721e19c9-cb90-4fa1-9256-a0ef9b3781ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine, text\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d60ee1c4-bc39-40a7-966c-6e9d314098ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('esports_db',)\n"
     ]
    }
   ],
   "source": [
    "DB_USER = \"root\"\n",
    "DB_PASS = \"\"\n",
    "DB_HOST = \"127.0.0.1\"\n",
    "DB_PORT = \"3306\"\n",
    "DB_NAME = \"esports_db\"\n",
    "\n",
    "engine = create_engine(f\"mysql+pymysql://{DB_USER}:{DB_PASS}@{DB_HOST}:{DB_PORT}/{DB_NAME}?charset=utf8mb4\")\n",
    "\n",
    "with engine.connect() as conn:\n",
    "    print(conn.execute(text(\"SELECT DATABASE()\")).fetchone())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c1034215-59c6-4bc1-a012-c0ef603ed392",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rows: (1967, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>day</th>\n",
       "      <th>qty_sold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2025-02-22</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13</td>\n",
       "      <td>2025-02-22</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19</td>\n",
       "      <td>2025-02-22</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17</td>\n",
       "      <td>2025-02-22</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2025-02-22</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   product_id         day  qty_sold\n",
       "0           2  2025-02-22       2.0\n",
       "1          13  2025-02-22       1.0\n",
       "2          19  2025-02-22       2.0\n",
       "3          17  2025-02-22       1.0\n",
       "4           4  2025-02-22       2.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "SELECT\n",
    "  oi.product_id AS product_id,\n",
    "  DATE(o.created_at) AS day,\n",
    "  SUM(oi.quantity) AS qty_sold\n",
    "FROM order_item oi\n",
    "JOIN `order` o ON o.id = oi.order_ref_id\n",
    "WHERE o.created_at >= DATE_SUB(CURDATE(), INTERVAL 365 DAY)\n",
    "GROUP BY oi.product_id, DATE(o.created_at)\n",
    "ORDER BY day ASC;\n",
    "\"\"\"\n",
    "\n",
    "df = pd.read_sql(query, engine)\n",
    "print(\"rows:\", df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b0e1b38d-e832-4b92-bf85-99c45cb4e3fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>day</th>\n",
       "      <th>product_id</th>\n",
       "      <th>qty_sold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-02-22</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-02-23</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-02-24</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-02-25</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-02-26</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         day  product_id  qty_sold\n",
       "0 2025-02-22           2       2.0\n",
       "1 2025-02-23           2       0.0\n",
       "2 2025-02-24           2       1.0\n",
       "3 2025-02-25           2       0.0\n",
       "4 2025-02-26           2       0.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"day\"] = pd.to_datetime(df[\"day\"])\n",
    "\n",
    "all_products = df[\"product_id\"].unique()\n",
    "full = []\n",
    "\n",
    "for pid in all_products:\n",
    "    sub = df[df[\"product_id\"] == pid].set_index(\"day\").sort_index()\n",
    "    # build full daily index\n",
    "    idx = pd.date_range(sub.index.min(), sub.index.max(), freq=\"D\")\n",
    "    sub = sub.reindex(idx, fill_value=0)\n",
    "    sub[\"product_id\"] = pid\n",
    "    sub = sub.rename_axis(\"day\").reset_index()\n",
    "    full.append(sub)\n",
    "\n",
    "data = pd.concat(full, ignore_index=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "18b5fff2-eb0a-4d32-93ac-471f8afd2690",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train rows: (5310, 12)\n"
     ]
    }
   ],
   "source": [
    "data = data.sort_values([\"product_id\", \"day\"])\n",
    "\n",
    "# lags\n",
    "for lag in [1, 2, 3, 7, 14, 30]:\n",
    "    data[f\"lag_{lag}\"] = data.groupby(\"product_id\")[\"qty_sold\"].shift(lag)\n",
    "\n",
    "# rolling averages\n",
    "data[\"roll_7\"]  = data.groupby(\"product_id\")[\"qty_sold\"].shift(1).rolling(7).mean()\n",
    "data[\"roll_14\"] = data.groupby(\"product_id\")[\"qty_sold\"].shift(1).rolling(14).mean()\n",
    "data[\"roll_30\"] = data.groupby(\"product_id\")[\"qty_sold\"].shift(1).rolling(30).mean()\n",
    "\n",
    "# day-of-week / month\n",
    "data[\"dow\"] = data[\"day\"].dt.dayofweek\n",
    "data[\"month\"] = data[\"day\"].dt.month\n",
    "\n",
    "# drop NaNs created by lags\n",
    "model_df = data.dropna().copy()\n",
    "\n",
    "X = model_df.drop(columns=[\"qty_sold\", \"day\"])\n",
    "y = model_df[\"qty_sold\"]\n",
    "\n",
    "print(\"train rows:\", X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "114d3919-e484-4c32-9741-ddd586c30201",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.9718993166968091\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True, random_state=42)\n",
    "\n",
    "model = RandomForestRegressor(\n",
    "    n_estimators=200,\n",
    "    random_state=42,\n",
    "    max_depth=12,\n",
    "    n_jobs=-1\n",
    ")\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "pred = model.predict(X_test)\n",
    "mae = mean_absolute_error(y_test, pred)\n",
    "print(\"MAE:\", mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bfdcb95d-997f-49b9-9d61-91421d733bc8",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The feature names should match those that were passed during fit.\nFeature names must be in the same order as they were in fit.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 48\u001b[0m\n\u001b[0;32m     46\u001b[0m forecasts \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m pid \u001b[38;5;129;01min\u001b[39;00m all_products:\n\u001b[1;32m---> 48\u001b[0m     out \u001b[38;5;241m=\u001b[39m forecast_product(\u001b[38;5;28mint\u001b[39m(pid))\n\u001b[0;32m     49\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m out:\n\u001b[0;32m     50\u001b[0m         forecasts\u001b[38;5;241m.\u001b[39mextend(out)\n",
      "Cell \u001b[1;32mIn[18], line 38\u001b[0m, in \u001b[0;36mforecast_product\u001b[1;34m(pid)\u001b[0m\n\u001b[0;32m     35\u001b[0m feat[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mroll_30\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m history\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m30\u001b[39m:]\u001b[38;5;241m.\u001b[39mmean() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(history) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m30\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m history\u001b[38;5;241m.\u001b[39mmean()\n\u001b[0;32m     37\u001b[0m Xf \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame([feat])\n\u001b[1;32m---> 38\u001b[0m yhat \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(model\u001b[38;5;241m.\u001b[39mpredict(Xf)[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m     39\u001b[0m yhat \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;241m0.0\u001b[39m, yhat)  \u001b[38;5;66;03m# no negative sales\u001b[39;00m\n\u001b[0;32m     41\u001b[0m future_rows\u001b[38;5;241m.\u001b[39mappend((pid, day, yhat))\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:1066\u001b[0m, in \u001b[0;36mForestRegressor.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m   1064\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m   1065\u001b[0m \u001b[38;5;66;03m# Check data\u001b[39;00m\n\u001b[1;32m-> 1066\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_X_predict(X)\n\u001b[0;32m   1068\u001b[0m \u001b[38;5;66;03m# Assign chunk of trees to jobs\u001b[39;00m\n\u001b[0;32m   1069\u001b[0m n_jobs, _, _ \u001b[38;5;241m=\u001b[39m _partition_estimators(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_estimators, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:638\u001b[0m, in \u001b[0;36mBaseForest._validate_X_predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    635\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    636\u001b[0m     ensure_all_finite \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 638\u001b[0m X \u001b[38;5;241m=\u001b[39m validate_data(\n\u001b[0;32m    639\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    640\u001b[0m     X,\n\u001b[0;32m    641\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mDTYPE,\n\u001b[0;32m    642\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    643\u001b[0m     reset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    644\u001b[0m     ensure_all_finite\u001b[38;5;241m=\u001b[39mensure_all_finite,\n\u001b[0;32m    645\u001b[0m )\n\u001b[0;32m    646\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m issparse(X) \u001b[38;5;129;01mand\u001b[39;00m (X\u001b[38;5;241m.\u001b[39mindices\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mintc \u001b[38;5;129;01mor\u001b[39;00m X\u001b[38;5;241m.\u001b[39mindptr\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mintc):\n\u001b[0;32m    647\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo support for np.int64 index based sparse matrices\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:2919\u001b[0m, in \u001b[0;36mvalidate_data\u001b[1;34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[0m\n\u001b[0;32m   2835\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mvalidate_data\u001b[39m(\n\u001b[0;32m   2836\u001b[0m     _estimator,\n\u001b[0;32m   2837\u001b[0m     \u001b[38;5;241m/\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2843\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params,\n\u001b[0;32m   2844\u001b[0m ):\n\u001b[0;32m   2845\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Validate input data and set or check feature names and counts of the input.\u001b[39;00m\n\u001b[0;32m   2846\u001b[0m \n\u001b[0;32m   2847\u001b[0m \u001b[38;5;124;03m    This helper function should be used in an estimator that requires input\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2917\u001b[0m \u001b[38;5;124;03m        validated.\u001b[39;00m\n\u001b[0;32m   2918\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2919\u001b[0m     _check_feature_names(_estimator, X, reset\u001b[38;5;241m=\u001b[39mreset)\n\u001b[0;32m   2920\u001b[0m     tags \u001b[38;5;241m=\u001b[39m get_tags(_estimator)\n\u001b[0;32m   2921\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m tags\u001b[38;5;241m.\u001b[39mtarget_tags\u001b[38;5;241m.\u001b[39mrequired:\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:2777\u001b[0m, in \u001b[0;36m_check_feature_names\u001b[1;34m(estimator, X, reset)\u001b[0m\n\u001b[0;32m   2774\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m missing_names \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m unexpected_names:\n\u001b[0;32m   2775\u001b[0m     message \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeature names must be in the same order as they were in fit.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 2777\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(message)\n",
      "\u001b[1;31mValueError\u001b[0m: The feature names should match those that were passed during fit.\nFeature names must be in the same order as they were in fit.\n"
     ]
    }
   ],
   "source": [
    "FORECAST_DAYS = 7\n",
    "today = pd.Timestamp.today().normalize()\n",
    "\n",
    "# current stock for reorder calculation\n",
    "stock_df = pd.read_sql(\"SELECT id AS product_id, stock FROM product\", engine)\n",
    "\n",
    "def forecast_product(pid: int):\n",
    "    sub = data[data[\"product_id\"] == pid].copy().sort_values(\"day\")\n",
    "    sub = sub.set_index(\"day\")\n",
    "\n",
    "    if sub.empty:\n",
    "        return None\n",
    "\n",
    "    # get last available day\n",
    "    last_day = sub.index.max()\n",
    "    history = sub[\"qty_sold\"].copy()\n",
    "\n",
    "    future_rows = []\n",
    "    for i in range(1, FORECAST_DAYS + 1):\n",
    "        day = last_day + pd.Timedelta(days=i)\n",
    "\n",
    "        # build feature row using last history\n",
    "        feat = {\n",
    "            \"product_id\": pid,\n",
    "            \"dow\": day.dayofweek,\n",
    "            \"month\": day.month,\n",
    "        }\n",
    "\n",
    "        for lag in [1, 2, 3, 7, 14, 30]:\n",
    "            feat[f\"lag_{lag}\"] = history.iloc[-lag] if len(history) >= lag else 0\n",
    "\n",
    "        # rolling (shifted)\n",
    "        feat[\"roll_7\"] = history.iloc[-7:].mean() if len(history) >= 7 else history.mean()\n",
    "        feat[\"roll_14\"] = history.iloc[-14:].mean() if len(history) >= 14 else history.mean()\n",
    "        feat[\"roll_30\"] = history.iloc[-30:].mean() if len(history) >= 30 else history.mean()\n",
    "\n",
    "        Xf = pd.DataFrame([feat])\n",
    "        yhat = float(model.predict(Xf)[0])\n",
    "        yhat = max(0.0, yhat)  # no negative sales\n",
    "\n",
    "        future_rows.append((pid, day, yhat))\n",
    "        history.loc[day] = yhat  # update history for next step\n",
    "\n",
    "    return future_rows\n",
    "\n",
    "forecasts = []\n",
    "for pid in all_products:\n",
    "    out = forecast_product(int(pid))\n",
    "    if out:\n",
    "        forecasts.extend(out)\n",
    "\n",
    "forecast_df = pd.DataFrame(forecasts, columns=[\"product_id\", \"day\", \"pred_qty\"])\n",
    "forecast_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "084da513-8012-4fc9-a5a9-1e34165d6397",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The feature names should match those that were passed during fit.\nFeature names must be in the same order as they were in fit.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 48\u001b[0m\n\u001b[0;32m     46\u001b[0m forecasts \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m pid \u001b[38;5;129;01min\u001b[39;00m all_products:\n\u001b[1;32m---> 48\u001b[0m     out \u001b[38;5;241m=\u001b[39m forecast_product(\u001b[38;5;28mint\u001b[39m(pid))\n\u001b[0;32m     49\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m out:\n\u001b[0;32m     50\u001b[0m         forecasts\u001b[38;5;241m.\u001b[39mextend(out)\n",
      "Cell \u001b[1;32mIn[19], line 38\u001b[0m, in \u001b[0;36mforecast_product\u001b[1;34m(pid)\u001b[0m\n\u001b[0;32m     35\u001b[0m feat[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mroll_30\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m history\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m30\u001b[39m:]\u001b[38;5;241m.\u001b[39mmean() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(history) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m30\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m history\u001b[38;5;241m.\u001b[39mmean()\n\u001b[0;32m     37\u001b[0m Xf \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame([feat])\n\u001b[1;32m---> 38\u001b[0m yhat \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(model\u001b[38;5;241m.\u001b[39mpredict(Xf)[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m     39\u001b[0m yhat \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;241m0.0\u001b[39m, yhat)  \u001b[38;5;66;03m# no negative sales\u001b[39;00m\n\u001b[0;32m     41\u001b[0m future_rows\u001b[38;5;241m.\u001b[39mappend((pid, day, yhat))\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:1066\u001b[0m, in \u001b[0;36mForestRegressor.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m   1064\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m   1065\u001b[0m \u001b[38;5;66;03m# Check data\u001b[39;00m\n\u001b[1;32m-> 1066\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_X_predict(X)\n\u001b[0;32m   1068\u001b[0m \u001b[38;5;66;03m# Assign chunk of trees to jobs\u001b[39;00m\n\u001b[0;32m   1069\u001b[0m n_jobs, _, _ \u001b[38;5;241m=\u001b[39m _partition_estimators(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_estimators, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:638\u001b[0m, in \u001b[0;36mBaseForest._validate_X_predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    635\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    636\u001b[0m     ensure_all_finite \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 638\u001b[0m X \u001b[38;5;241m=\u001b[39m validate_data(\n\u001b[0;32m    639\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    640\u001b[0m     X,\n\u001b[0;32m    641\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mDTYPE,\n\u001b[0;32m    642\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    643\u001b[0m     reset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    644\u001b[0m     ensure_all_finite\u001b[38;5;241m=\u001b[39mensure_all_finite,\n\u001b[0;32m    645\u001b[0m )\n\u001b[0;32m    646\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m issparse(X) \u001b[38;5;129;01mand\u001b[39;00m (X\u001b[38;5;241m.\u001b[39mindices\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mintc \u001b[38;5;129;01mor\u001b[39;00m X\u001b[38;5;241m.\u001b[39mindptr\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mintc):\n\u001b[0;32m    647\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo support for np.int64 index based sparse matrices\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:2919\u001b[0m, in \u001b[0;36mvalidate_data\u001b[1;34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[0m\n\u001b[0;32m   2835\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mvalidate_data\u001b[39m(\n\u001b[0;32m   2836\u001b[0m     _estimator,\n\u001b[0;32m   2837\u001b[0m     \u001b[38;5;241m/\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2843\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params,\n\u001b[0;32m   2844\u001b[0m ):\n\u001b[0;32m   2845\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Validate input data and set or check feature names and counts of the input.\u001b[39;00m\n\u001b[0;32m   2846\u001b[0m \n\u001b[0;32m   2847\u001b[0m \u001b[38;5;124;03m    This helper function should be used in an estimator that requires input\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2917\u001b[0m \u001b[38;5;124;03m        validated.\u001b[39;00m\n\u001b[0;32m   2918\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2919\u001b[0m     _check_feature_names(_estimator, X, reset\u001b[38;5;241m=\u001b[39mreset)\n\u001b[0;32m   2920\u001b[0m     tags \u001b[38;5;241m=\u001b[39m get_tags(_estimator)\n\u001b[0;32m   2921\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m tags\u001b[38;5;241m.\u001b[39mtarget_tags\u001b[38;5;241m.\u001b[39mrequired:\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:2777\u001b[0m, in \u001b[0;36m_check_feature_names\u001b[1;34m(estimator, X, reset)\u001b[0m\n\u001b[0;32m   2774\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m missing_names \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m unexpected_names:\n\u001b[0;32m   2775\u001b[0m     message \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeature names must be in the same order as they were in fit.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 2777\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(message)\n",
      "\u001b[1;31mValueError\u001b[0m: The feature names should match those that were passed during fit.\nFeature names must be in the same order as they were in fit.\n"
     ]
    }
   ],
   "source": [
    "FORECAST_DAYS = 7\n",
    "today = pd.Timestamp.today().normalize()\n",
    "\n",
    "# current stock for reorder calculation\n",
    "stock_df = pd.read_sql(\"SELECT id AS product_id, stock FROM product\", engine)\n",
    "\n",
    "def forecast_product(pid: int):\n",
    "    sub = data[data[\"product_id\"] == pid].copy().sort_values(\"day\")\n",
    "    sub = sub.set_index(\"day\")\n",
    "\n",
    "    if sub.empty:\n",
    "        return None\n",
    "\n",
    "    # get last available day\n",
    "    last_day = sub.index.max()\n",
    "    history = sub[\"qty_sold\"].copy()\n",
    "\n",
    "    future_rows = []\n",
    "    for i in range(1, FORECAST_DAYS + 1):\n",
    "        day = last_day + pd.Timedelta(days=i)\n",
    "\n",
    "        # build feature row using last history\n",
    "        feat = {\n",
    "            \"product_id\": pid,\n",
    "            \"dow\": day.dayofweek,\n",
    "            \"month\": day.month,\n",
    "        }\n",
    "\n",
    "        for lag in [1, 2, 3, 7, 14, 30]:\n",
    "            feat[f\"lag_{lag}\"] = history.iloc[-lag] if len(history) >= lag else 0\n",
    "\n",
    "        # rolling (shifted)\n",
    "        feat[\"roll_7\"] = history.iloc[-7:].mean() if len(history) >= 7 else history.mean()\n",
    "        feat[\"roll_14\"] = history.iloc[-14:].mean() if len(history) >= 14 else history.mean()\n",
    "        feat[\"roll_30\"] = history.iloc[-30:].mean() if len(history) >= 30 else history.mean()\n",
    "\n",
    "        Xf = pd.DataFrame([feat])\n",
    "        yhat = float(model.predict(Xf)[0])\n",
    "        yhat = max(0.0, yhat)  # no negative sales\n",
    "\n",
    "        future_rows.append((pid, day, yhat))\n",
    "        history.loc[day] = yhat  # update history for next step\n",
    "\n",
    "    return future_rows\n",
    "\n",
    "forecasts = []\n",
    "for pid in all_products:\n",
    "    out = forecast_product(int(pid))\n",
    "    if out:\n",
    "        forecasts.extend(out)\n",
    "\n",
    "forecast_df = pd.DataFrame(forecasts, columns=[\"product_id\", \"day\", \"pred_qty\"])\n",
    "forecast_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d8dc8e0f-6c06-4607-a516-5cf0aefe5120",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>day</th>\n",
       "      <th>pred_qty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2026-02-22</td>\n",
       "      <td>1.104607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2026-02-23</td>\n",
       "      <td>0.721009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2026-02-24</td>\n",
       "      <td>1.505160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2026-02-25</td>\n",
       "      <td>0.547481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2026-02-26</td>\n",
       "      <td>0.594919</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   product_id        day  pred_qty\n",
       "0           2 2026-02-22  1.104607\n",
       "1           2 2026-02-23  0.721009\n",
       "2           2 2026-02-24  1.505160\n",
       "3           2 2026-02-25  0.547481\n",
       "4           2 2026-02-26  0.594919"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FORECAST_DAYS = 7\n",
    "today = pd.Timestamp.today().normalize()\n",
    "\n",
    "# current stock for reorder calculation\n",
    "stock_df = pd.read_sql(\"SELECT id AS product_id, stock FROM product\", engine)\n",
    "\n",
    "# ✅ IMPORTANT: keep the exact feature order used in training\n",
    "FEATURE_COLS = list(X_train.columns)\n",
    "\n",
    "def forecast_product(pid: int):\n",
    "    sub = data[data[\"product_id\"] == pid].copy().sort_values(\"day\")\n",
    "    sub = sub.set_index(\"day\")\n",
    "\n",
    "    if sub.empty:\n",
    "        return None\n",
    "\n",
    "    last_day = sub.index.max()\n",
    "    history = sub[\"qty_sold\"].copy()\n",
    "\n",
    "    future_rows = []\n",
    "    for i in range(1, FORECAST_DAYS + 1):\n",
    "        day = last_day + pd.Timedelta(days=i)\n",
    "\n",
    "        feat = {}\n",
    "\n",
    "        # must include all features exactly like training\n",
    "        feat[\"product_id\"] = pid\n",
    "        feat[\"dow\"] = day.dayofweek\n",
    "        feat[\"month\"] = day.month\n",
    "\n",
    "        for lag in [1, 2, 3, 7, 14, 30]:\n",
    "            feat[f\"lag_{lag}\"] = float(history.iloc[-lag]) if len(history) >= lag else 0.0\n",
    "\n",
    "        feat[\"roll_7\"]  = float(history.iloc[-7:].mean())  if len(history) >= 7  else float(history.mean())\n",
    "        feat[\"roll_14\"] = float(history.iloc[-14:].mean()) if len(history) >= 14 else float(history.mean())\n",
    "        feat[\"roll_30\"] = float(history.iloc[-30:].mean()) if len(history) >= 30 else float(history.mean())\n",
    "\n",
    "        # ✅ create dataframe and reindex to match training feature order\n",
    "        Xf = pd.DataFrame([feat]).reindex(columns=FEATURE_COLS)\n",
    "\n",
    "        # (safety) fill any missing columns with 0\n",
    "        Xf = Xf.fillna(0)\n",
    "\n",
    "        yhat = float(model.predict(Xf)[0])\n",
    "        yhat = max(0.0, yhat)\n",
    "\n",
    "        future_rows.append((pid, day, yhat))\n",
    "        history.loc[day] = yhat\n",
    "\n",
    "    return future_rows\n",
    "\n",
    "forecasts = []\n",
    "for pid in all_products:\n",
    "    out = forecast_product(int(pid))\n",
    "    if out:\n",
    "        forecasts.extend(out)\n",
    "\n",
    "forecast_df = pd.DataFrame(forecasts, columns=[\"product_id\", \"day\", \"pred_qty\"])\n",
    "forecast_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2341a5d7-9caf-4158-8f7a-6c3825d9935e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((112, 3),\n",
       "    product_id        day  pred_qty\n",
       " 0           2 2026-02-22  1.104607\n",
       " 1           2 2026-02-23  0.721009\n",
       " 2           2 2026-02-24  1.505160\n",
       " 3           2 2026-02-25  0.547481\n",
       " 4           2 2026-02-26  0.594919)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_df.shape, forecast_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "70185c4c-ed00-4d05-9fe9-058528540fd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>forecast_days</th>\n",
       "      <th>predicted_qty</th>\n",
       "      <th>recommended_reorder_qty</th>\n",
       "      <th>generated_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>5.95</td>\n",
       "      <td>0</td>\n",
       "      <td>2026-02-22 00:59:55.183192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>4.77</td>\n",
       "      <td>5</td>\n",
       "      <td>2026-02-22 00:59:55.183192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>5.06</td>\n",
       "      <td>0</td>\n",
       "      <td>2026-02-22 00:59:55.183192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>4.53</td>\n",
       "      <td>0</td>\n",
       "      <td>2026-02-22 00:59:55.183192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>5.06</td>\n",
       "      <td>0</td>\n",
       "      <td>2026-02-22 00:59:55.183192</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   product_id  forecast_days  predicted_qty  recommended_reorder_qty  \\\n",
       "0           2              7           5.95                        0   \n",
       "1           4              7           4.77                        5   \n",
       "2           5              7           5.06                        0   \n",
       "3           6              7           4.53                        0   \n",
       "4           7              7           5.06                        0   \n",
       "\n",
       "                generated_at  \n",
       "0 2026-02-22 00:59:55.183192  \n",
       "1 2026-02-22 00:59:55.183192  \n",
       "2 2026-02-22 00:59:55.183192  \n",
       "3 2026-02-22 00:59:55.183192  \n",
       "4 2026-02-22 00:59:55.183192  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === STEP 8: aggregate + save to DB ===\n",
    "\n",
    "FORECAST_DAYS = 7\n",
    "\n",
    "# 1) total predicted qty for next 7 days per product\n",
    "sum_df = (\n",
    "    forecast_df.groupby(\"product_id\", as_index=False)[\"pred_qty\"]\n",
    "    .sum()\n",
    "    .rename(columns={\"pred_qty\": \"predicted_qty\"})\n",
    ")\n",
    "\n",
    "# 2) join stock\n",
    "sum_df = sum_df.merge(stock_df, on=\"product_id\", how=\"left\")\n",
    "sum_df[\"stock\"] = sum_df[\"stock\"].fillna(0).astype(int)\n",
    "\n",
    "# 3) recommended reorder: ceil(predicted - stock), minimum 0\n",
    "sum_df[\"recommended_reorder_qty\"] = (\n",
    "    (sum_df[\"predicted_qty\"] - sum_df[\"stock\"])\n",
    "    .apply(lambda x: int(np.ceil(x)) if x > 0 else 0)\n",
    ")\n",
    "\n",
    "sum_df[\"forecast_days\"] = FORECAST_DAYS\n",
    "sum_df[\"generated_at\"] = pd.Timestamp.now()\n",
    "\n",
    "# 4) insert into product_forecast\n",
    "insert_df = sum_df[[\"product_id\", \"forecast_days\", \"predicted_qty\", \"recommended_reorder_qty\", \"generated_at\"]].copy()\n",
    "insert_df[\"predicted_qty\"] = insert_df[\"predicted_qty\"].round(2)\n",
    "\n",
    "# optional: clean previous forecasts for same horizon (keeps table clean)\n",
    "with engine.begin() as conn:\n",
    "    conn.execute(text(\"DELETE FROM product_forecast WHERE forecast_days = :d\"), {\"d\": FORECAST_DAYS})\n",
    "\n",
    "insert_df.to_sql(\"product_forecast\", engine, if_exists=\"append\", index=False)\n",
    "\n",
    "insert_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8170ccbe-d4b1-4e2c-89fb-0c57d1c8e74d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    n\n",
       "0  16"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_sql(\"SELECT COUNT(*) AS n FROM product_forecast\", engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "104b3141-c8cc-465c-a9ef-329c3202f080",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Orders without items: 26\n"
     ]
    },
    {
     "ename": "IntegrityError",
     "evalue": "(pymysql.err.IntegrityError) (1062, \"Duplicate entry '28-15' for key 'PRIMARY'\")\n[SQL: INSERT INTO order_product (order_id, product_id) VALUES (%(order_id)s, %(product_id)s)]\n[parameters: [{'order_id': 5, 'product_id': 17}, {'order_id': 7, 'product_id': 18}, {'order_id': 7, 'product_id': 11}, {'order_id': 8, 'product_id': 13}, {'order_id': 9, 'product_id': 17}, {'order_id': 9, 'product_id': 15}, {'order_id': 9, 'product_id': 19}, {'order_id': 10, 'product_id': 5}  ... displaying 10 of 52 total bound parameter sets ...  {'order_id': 33, 'product_id': 6}, {'order_id': 34, 'product_id': 11}]]\n(Background on this error at: https://sqlalche.me/e/20/gkpj)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIntegrityError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:1933\u001b[0m, in \u001b[0;36mConnection._exec_single_context\u001b[1;34m(self, dialect, context, statement, parameters)\u001b[0m\n\u001b[0;32m   1932\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m evt_handled:\n\u001b[1;32m-> 1933\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdialect\u001b[38;5;241m.\u001b[39mdo_executemany(\n\u001b[0;32m   1934\u001b[0m             cursor,\n\u001b[0;32m   1935\u001b[0m             str_statement,\n\u001b[0;32m   1936\u001b[0m             effective_parameters,\n\u001b[0;32m   1937\u001b[0m             context,\n\u001b[0;32m   1938\u001b[0m         )\n\u001b[0;32m   1939\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m effective_parameters \u001b[38;5;129;01mand\u001b[39;00m context\u001b[38;5;241m.\u001b[39mno_parameters:\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\sqlalchemy\\dialects\\mysql\\mysqldb.py:172\u001b[0m, in \u001b[0;36mMySQLDialect_mysqldb.do_executemany\u001b[1;34m(self, cursor, statement, parameters, context)\u001b[0m\n\u001b[0;32m    171\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdo_executemany\u001b[39m(\u001b[38;5;28mself\u001b[39m, cursor, statement, parameters, context\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m--> 172\u001b[0m     rowcount \u001b[38;5;241m=\u001b[39m cursor\u001b[38;5;241m.\u001b[39mexecutemany(statement, parameters)\n\u001b[0;32m    173\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\pymysql\\cursors.py:182\u001b[0m, in \u001b[0;36mCursor.executemany\u001b[1;34m(self, query, args)\u001b[0m\n\u001b[0;32m    181\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m q_values[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m q_values[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 182\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_do_execute_many(\n\u001b[0;32m    183\u001b[0m         q_prefix,\n\u001b[0;32m    184\u001b[0m         q_values,\n\u001b[0;32m    185\u001b[0m         q_postfix,\n\u001b[0;32m    186\u001b[0m         args,\n\u001b[0;32m    187\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_stmt_length,\n\u001b[0;32m    188\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_db()\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    189\u001b[0m     )\n\u001b[0;32m    191\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrowcount \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecute(query, arg) \u001b[38;5;28;01mfor\u001b[39;00m arg \u001b[38;5;129;01min\u001b[39;00m args)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\pymysql\\cursors.py:220\u001b[0m, in \u001b[0;36mCursor._do_execute_many\u001b[1;34m(self, prefix, values, postfix, args, max_stmt_length, encoding)\u001b[0m\n\u001b[0;32m    219\u001b[0m     sql \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m v\n\u001b[1;32m--> 220\u001b[0m rows \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecute(sql \u001b[38;5;241m+\u001b[39m postfix)\n\u001b[0;32m    221\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrowcount \u001b[38;5;241m=\u001b[39m rows\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\pymysql\\cursors.py:153\u001b[0m, in \u001b[0;36mCursor.execute\u001b[1;34m(self, query, args)\u001b[0m\n\u001b[0;32m    151\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmogrify(query, args)\n\u001b[1;32m--> 153\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_query(query)\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_executed \u001b[38;5;241m=\u001b[39m query\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\pymysql\\cursors.py:322\u001b[0m, in \u001b[0;36mCursor._query\u001b[1;34m(self, q)\u001b[0m\n\u001b[0;32m    321\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_clear_result()\n\u001b[1;32m--> 322\u001b[0m conn\u001b[38;5;241m.\u001b[39mquery(q)\n\u001b[0;32m    323\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_do_get_result()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\pymysql\\connections.py:575\u001b[0m, in \u001b[0;36mConnection.query\u001b[1;34m(self, sql, unbuffered)\u001b[0m\n\u001b[0;32m    574\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_execute_command(COMMAND\u001b[38;5;241m.\u001b[39mCOM_QUERY, sql)\n\u001b[1;32m--> 575\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_affected_rows \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read_query_result(unbuffered\u001b[38;5;241m=\u001b[39munbuffered)\n\u001b[0;32m    576\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_affected_rows\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\pymysql\\connections.py:826\u001b[0m, in \u001b[0;36mConnection._read_query_result\u001b[1;34m(self, unbuffered)\u001b[0m\n\u001b[0;32m    825\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 826\u001b[0m     result\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m    827\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result \u001b[38;5;241m=\u001b[39m result\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\pymysql\\connections.py:1203\u001b[0m, in \u001b[0;36mMySQLResult.read\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1202\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1203\u001b[0m     first_packet \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconnection\u001b[38;5;241m.\u001b[39m_read_packet()\n\u001b[0;32m   1205\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m first_packet\u001b[38;5;241m.\u001b[39mis_ok_packet():\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\pymysql\\connections.py:782\u001b[0m, in \u001b[0;36mConnection._read_packet\u001b[1;34m(self, packet_type)\u001b[0m\n\u001b[0;32m    781\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\u001b[38;5;241m.\u001b[39munbuffered_active \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m--> 782\u001b[0m     packet\u001b[38;5;241m.\u001b[39mraise_for_error()\n\u001b[0;32m    783\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m packet\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\pymysql\\protocol.py:219\u001b[0m, in \u001b[0;36mMysqlPacket.raise_for_error\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merrno =\u001b[39m\u001b[38;5;124m\"\u001b[39m, errno)\n\u001b[1;32m--> 219\u001b[0m err\u001b[38;5;241m.\u001b[39mraise_mysql_exception(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\pymysql\\err.py:150\u001b[0m, in \u001b[0;36mraise_mysql_exception\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    149\u001b[0m     errorclass \u001b[38;5;241m=\u001b[39m InternalError \u001b[38;5;28;01mif\u001b[39;00m errno \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1000\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m OperationalError\n\u001b[1;32m--> 150\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m errorclass(errno, errval)\n",
      "\u001b[1;31mIntegrityError\u001b[0m: (1062, \"Duplicate entry '28-15' for key 'PRIMARY'\")",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mIntegrityError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 63\u001b[0m\n\u001b[0;32m     60\u001b[0m df_items\u001b[38;5;241m.\u001b[39mto_sql(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124morder_item\u001b[39m\u001b[38;5;124m\"\u001b[39m, engine, if_exists\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mappend\u001b[39m\u001b[38;5;124m\"\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     62\u001b[0m \u001b[38;5;66;03m# 3) insert order_product (avoid duplicates just in case)\u001b[39;00m\n\u001b[1;32m---> 63\u001b[0m df_op\u001b[38;5;241m.\u001b[39mto_sql(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124morder_product\u001b[39m\u001b[38;5;124m\"\u001b[39m, engine, if_exists\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mappend\u001b[39m\u001b[38;5;124m\"\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     65\u001b[0m \u001b[38;5;66;03m# 4) update order.total_amount\u001b[39;00m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m engine\u001b[38;5;241m.\u001b[39mbegin() \u001b[38;5;28;01mas\u001b[39;00m conn:\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\util\\_decorators.py:333\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    328\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    329\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    330\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    331\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    332\u001b[0m     )\n\u001b[1;32m--> 333\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:3087\u001b[0m, in \u001b[0;36mNDFrame.to_sql\u001b[1;34m(self, name, con, schema, if_exists, index, index_label, chunksize, dtype, method)\u001b[0m\n\u001b[0;32m   2889\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   2890\u001b[0m \u001b[38;5;124;03mWrite records stored in a DataFrame to a SQL database.\u001b[39;00m\n\u001b[0;32m   2891\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3083\u001b[0m \u001b[38;5;124;03m[(1,), (None,), (2,)]\u001b[39;00m\n\u001b[0;32m   3084\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m  \u001b[38;5;66;03m# noqa: E501\u001b[39;00m\n\u001b[0;32m   3085\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m sql\n\u001b[1;32m-> 3087\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m sql\u001b[38;5;241m.\u001b[39mto_sql(\n\u001b[0;32m   3088\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   3089\u001b[0m     name,\n\u001b[0;32m   3090\u001b[0m     con,\n\u001b[0;32m   3091\u001b[0m     schema\u001b[38;5;241m=\u001b[39mschema,\n\u001b[0;32m   3092\u001b[0m     if_exists\u001b[38;5;241m=\u001b[39mif_exists,\n\u001b[0;32m   3093\u001b[0m     index\u001b[38;5;241m=\u001b[39mindex,\n\u001b[0;32m   3094\u001b[0m     index_label\u001b[38;5;241m=\u001b[39mindex_label,\n\u001b[0;32m   3095\u001b[0m     chunksize\u001b[38;5;241m=\u001b[39mchunksize,\n\u001b[0;32m   3096\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[0;32m   3097\u001b[0m     method\u001b[38;5;241m=\u001b[39mmethod,\n\u001b[0;32m   3098\u001b[0m )\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\io\\sql.py:842\u001b[0m, in \u001b[0;36mto_sql\u001b[1;34m(frame, name, con, schema, if_exists, index, index_label, chunksize, dtype, method, engine, **engine_kwargs)\u001b[0m\n\u001b[0;32m    837\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[0;32m    838\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mframe\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m argument should be either a Series or a DataFrame\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    839\u001b[0m     )\n\u001b[0;32m    841\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m pandasSQL_builder(con, schema\u001b[38;5;241m=\u001b[39mschema, need_transaction\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m pandas_sql:\n\u001b[1;32m--> 842\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pandas_sql\u001b[38;5;241m.\u001b[39mto_sql(\n\u001b[0;32m    843\u001b[0m         frame,\n\u001b[0;32m    844\u001b[0m         name,\n\u001b[0;32m    845\u001b[0m         if_exists\u001b[38;5;241m=\u001b[39mif_exists,\n\u001b[0;32m    846\u001b[0m         index\u001b[38;5;241m=\u001b[39mindex,\n\u001b[0;32m    847\u001b[0m         index_label\u001b[38;5;241m=\u001b[39mindex_label,\n\u001b[0;32m    848\u001b[0m         schema\u001b[38;5;241m=\u001b[39mschema,\n\u001b[0;32m    849\u001b[0m         chunksize\u001b[38;5;241m=\u001b[39mchunksize,\n\u001b[0;32m    850\u001b[0m         dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[0;32m    851\u001b[0m         method\u001b[38;5;241m=\u001b[39mmethod,\n\u001b[0;32m    852\u001b[0m         engine\u001b[38;5;241m=\u001b[39mengine,\n\u001b[0;32m    853\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mengine_kwargs,\n\u001b[0;32m    854\u001b[0m     )\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\io\\sql.py:2018\u001b[0m, in \u001b[0;36mSQLDatabase.to_sql\u001b[1;34m(self, frame, name, if_exists, index, index_label, schema, chunksize, dtype, method, engine, **engine_kwargs)\u001b[0m\n\u001b[0;32m   2006\u001b[0m sql_engine \u001b[38;5;241m=\u001b[39m get_engine(engine)\n\u001b[0;32m   2008\u001b[0m table \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprep_table(\n\u001b[0;32m   2009\u001b[0m     frame\u001b[38;5;241m=\u001b[39mframe,\n\u001b[0;32m   2010\u001b[0m     name\u001b[38;5;241m=\u001b[39mname,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2015\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[0;32m   2016\u001b[0m )\n\u001b[1;32m-> 2018\u001b[0m total_inserted \u001b[38;5;241m=\u001b[39m sql_engine\u001b[38;5;241m.\u001b[39minsert_records(\n\u001b[0;32m   2019\u001b[0m     table\u001b[38;5;241m=\u001b[39mtable,\n\u001b[0;32m   2020\u001b[0m     con\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcon,\n\u001b[0;32m   2021\u001b[0m     frame\u001b[38;5;241m=\u001b[39mframe,\n\u001b[0;32m   2022\u001b[0m     name\u001b[38;5;241m=\u001b[39mname,\n\u001b[0;32m   2023\u001b[0m     index\u001b[38;5;241m=\u001b[39mindex,\n\u001b[0;32m   2024\u001b[0m     schema\u001b[38;5;241m=\u001b[39mschema,\n\u001b[0;32m   2025\u001b[0m     chunksize\u001b[38;5;241m=\u001b[39mchunksize,\n\u001b[0;32m   2026\u001b[0m     method\u001b[38;5;241m=\u001b[39mmethod,\n\u001b[0;32m   2027\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mengine_kwargs,\n\u001b[0;32m   2028\u001b[0m )\n\u001b[0;32m   2030\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_case_sensitive(name\u001b[38;5;241m=\u001b[39mname, schema\u001b[38;5;241m=\u001b[39mschema)\n\u001b[0;32m   2031\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m total_inserted\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\io\\sql.py:1567\u001b[0m, in \u001b[0;36mSQLAlchemyEngine.insert_records\u001b[1;34m(self, table, con, frame, name, index, schema, chunksize, method, **engine_kwargs)\u001b[0m\n\u001b[0;32m   1565\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m re\u001b[38;5;241m.\u001b[39msearch(msg, err_text):\n\u001b[0;32m   1566\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minf cannot be used with MySQL\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m-> 1567\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m err\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\io\\sql.py:1558\u001b[0m, in \u001b[0;36mSQLAlchemyEngine.insert_records\u001b[1;34m(self, table, con, frame, name, index, schema, chunksize, method, **engine_kwargs)\u001b[0m\n\u001b[0;32m   1555\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msqlalchemy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m exc\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1558\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m table\u001b[38;5;241m.\u001b[39minsert(chunksize\u001b[38;5;241m=\u001b[39mchunksize, method\u001b[38;5;241m=\u001b[39mmethod)\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m exc\u001b[38;5;241m.\u001b[39mStatementError \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m   1560\u001b[0m     \u001b[38;5;66;03m# GH34431\u001b[39;00m\n\u001b[0;32m   1561\u001b[0m     \u001b[38;5;66;03m# https://stackoverflow.com/a/67358288/6067848\u001b[39;00m\n\u001b[0;32m   1562\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m(1054, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown column \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minf(e0)?\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m in \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfield list\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m))(?#\u001b[39m\n\u001b[0;32m   1563\u001b[0m \u001b[38;5;124m    )|inf can not be used with MySQL\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\io\\sql.py:1119\u001b[0m, in \u001b[0;36mSQLTable.insert\u001b[1;34m(self, chunksize, method)\u001b[0m\n\u001b[0;32m   1116\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m   1118\u001b[0m chunk_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39m(arr[start_i:end_i] \u001b[38;5;28;01mfor\u001b[39;00m arr \u001b[38;5;129;01min\u001b[39;00m data_list))\n\u001b[1;32m-> 1119\u001b[0m num_inserted \u001b[38;5;241m=\u001b[39m exec_insert(conn, keys, chunk_iter)\n\u001b[0;32m   1120\u001b[0m \u001b[38;5;66;03m# GH 46891\u001b[39;00m\n\u001b[0;32m   1121\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_inserted \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\io\\sql.py:1010\u001b[0m, in \u001b[0;36mSQLTable._execute_insert\u001b[1;34m(self, conn, keys, data_iter)\u001b[0m\n\u001b[0;32m    998\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    999\u001b[0m \u001b[38;5;124;03mExecute SQL statement inserting data\u001b[39;00m\n\u001b[0;32m   1000\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1007\u001b[0m \u001b[38;5;124;03m   Each item contains a list of values to be inserted\u001b[39;00m\n\u001b[0;32m   1008\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1009\u001b[0m data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mzip\u001b[39m(keys, row)) \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m data_iter]\n\u001b[1;32m-> 1010\u001b[0m result \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39mexecute(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtable\u001b[38;5;241m.\u001b[39minsert(), data)\n\u001b[0;32m   1011\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\u001b[38;5;241m.\u001b[39mrowcount\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:1416\u001b[0m, in \u001b[0;36mConnection.execute\u001b[1;34m(self, statement, parameters, execution_options)\u001b[0m\n\u001b[0;32m   1414\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\u001b[38;5;241m.\u001b[39mObjectNotExecutableError(statement) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   1415\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1416\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m meth(\n\u001b[0;32m   1417\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1418\u001b[0m         distilled_parameters,\n\u001b[0;32m   1419\u001b[0m         execution_options \u001b[38;5;129;01mor\u001b[39;00m NO_OPTIONS,\n\u001b[0;32m   1420\u001b[0m     )\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\sqlalchemy\\sql\\elements.py:523\u001b[0m, in \u001b[0;36mClauseElement._execute_on_connection\u001b[1;34m(self, connection, distilled_params, execution_options)\u001b[0m\n\u001b[0;32m    521\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m TYPE_CHECKING:\n\u001b[0;32m    522\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, Executable)\n\u001b[1;32m--> 523\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m connection\u001b[38;5;241m.\u001b[39m_execute_clauseelement(\n\u001b[0;32m    524\u001b[0m         \u001b[38;5;28mself\u001b[39m, distilled_params, execution_options\n\u001b[0;32m    525\u001b[0m     )\n\u001b[0;32m    526\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    527\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\u001b[38;5;241m.\u001b[39mObjectNotExecutableError(\u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:1638\u001b[0m, in \u001b[0;36mConnection._execute_clauseelement\u001b[1;34m(self, elem, distilled_parameters, execution_options)\u001b[0m\n\u001b[0;32m   1626\u001b[0m compiled_cache: Optional[CompiledCacheType] \u001b[38;5;241m=\u001b[39m execution_options\u001b[38;5;241m.\u001b[39mget(\n\u001b[0;32m   1627\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompiled_cache\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine\u001b[38;5;241m.\u001b[39m_compiled_cache\n\u001b[0;32m   1628\u001b[0m )\n\u001b[0;32m   1630\u001b[0m compiled_sql, extracted_params, cache_hit \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39m_compile_w_cache(\n\u001b[0;32m   1631\u001b[0m     dialect\u001b[38;5;241m=\u001b[39mdialect,\n\u001b[0;32m   1632\u001b[0m     compiled_cache\u001b[38;5;241m=\u001b[39mcompiled_cache,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1636\u001b[0m     linting\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdialect\u001b[38;5;241m.\u001b[39mcompiler_linting \u001b[38;5;241m|\u001b[39m compiler\u001b[38;5;241m.\u001b[39mWARN_LINTING,\n\u001b[0;32m   1637\u001b[0m )\n\u001b[1;32m-> 1638\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_execute_context(\n\u001b[0;32m   1639\u001b[0m     dialect,\n\u001b[0;32m   1640\u001b[0m     dialect\u001b[38;5;241m.\u001b[39mexecution_ctx_cls\u001b[38;5;241m.\u001b[39m_init_compiled,\n\u001b[0;32m   1641\u001b[0m     compiled_sql,\n\u001b[0;32m   1642\u001b[0m     distilled_parameters,\n\u001b[0;32m   1643\u001b[0m     execution_options,\n\u001b[0;32m   1644\u001b[0m     compiled_sql,\n\u001b[0;32m   1645\u001b[0m     distilled_parameters,\n\u001b[0;32m   1646\u001b[0m     elem,\n\u001b[0;32m   1647\u001b[0m     extracted_params,\n\u001b[0;32m   1648\u001b[0m     cache_hit\u001b[38;5;241m=\u001b[39mcache_hit,\n\u001b[0;32m   1649\u001b[0m )\n\u001b[0;32m   1650\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_events:\n\u001b[0;32m   1651\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch\u001b[38;5;241m.\u001b[39mafter_execute(\n\u001b[0;32m   1652\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1653\u001b[0m         elem,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1657\u001b[0m         ret,\n\u001b[0;32m   1658\u001b[0m     )\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:1843\u001b[0m, in \u001b[0;36mConnection._execute_context\u001b[1;34m(self, dialect, constructor, statement, parameters, execution_options, *args, **kw)\u001b[0m\n\u001b[0;32m   1841\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exec_insertmany_context(dialect, context)\n\u001b[0;32m   1842\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1843\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exec_single_context(\n\u001b[0;32m   1844\u001b[0m         dialect, context, statement, parameters\n\u001b[0;32m   1845\u001b[0m     )\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:1983\u001b[0m, in \u001b[0;36mConnection._exec_single_context\u001b[1;34m(self, dialect, context, statement, parameters)\u001b[0m\n\u001b[0;32m   1980\u001b[0m     result \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39m_setup_result_proxy()\n\u001b[0;32m   1982\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m-> 1983\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_dbapi_exception(\n\u001b[0;32m   1984\u001b[0m         e, str_statement, effective_parameters, cursor, context\n\u001b[0;32m   1985\u001b[0m     )\n\u001b[0;32m   1987\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:2352\u001b[0m, in \u001b[0;36mConnection._handle_dbapi_exception\u001b[1;34m(self, e, statement, parameters, cursor, context, is_sub_exec)\u001b[0m\n\u001b[0;32m   2350\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m should_wrap:\n\u001b[0;32m   2351\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m sqlalchemy_exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 2352\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m sqlalchemy_exception\u001b[38;5;241m.\u001b[39mwith_traceback(exc_info[\u001b[38;5;241m2\u001b[39m]) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m   2353\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2354\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m exc_info[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:1933\u001b[0m, in \u001b[0;36mConnection._exec_single_context\u001b[1;34m(self, dialect, context, statement, parameters)\u001b[0m\n\u001b[0;32m   1931\u001b[0m                 \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m   1932\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m evt_handled:\n\u001b[1;32m-> 1933\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdialect\u001b[38;5;241m.\u001b[39mdo_executemany(\n\u001b[0;32m   1934\u001b[0m             cursor,\n\u001b[0;32m   1935\u001b[0m             str_statement,\n\u001b[0;32m   1936\u001b[0m             effective_parameters,\n\u001b[0;32m   1937\u001b[0m             context,\n\u001b[0;32m   1938\u001b[0m         )\n\u001b[0;32m   1939\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m effective_parameters \u001b[38;5;129;01mand\u001b[39;00m context\u001b[38;5;241m.\u001b[39mno_parameters:\n\u001b[0;32m   1940\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdialect\u001b[38;5;241m.\u001b[39m_has_events:\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\sqlalchemy\\dialects\\mysql\\mysqldb.py:172\u001b[0m, in \u001b[0;36mMySQLDialect_mysqldb.do_executemany\u001b[1;34m(self, cursor, statement, parameters, context)\u001b[0m\n\u001b[0;32m    171\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdo_executemany\u001b[39m(\u001b[38;5;28mself\u001b[39m, cursor, statement, parameters, context\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m--> 172\u001b[0m     rowcount \u001b[38;5;241m=\u001b[39m cursor\u001b[38;5;241m.\u001b[39mexecutemany(statement, parameters)\n\u001b[0;32m    173\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    174\u001b[0m         context\u001b[38;5;241m.\u001b[39m_rowcount \u001b[38;5;241m=\u001b[39m rowcount\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\pymysql\\cursors.py:182\u001b[0m, in \u001b[0;36mCursor.executemany\u001b[1;34m(self, query, args)\u001b[0m\n\u001b[0;32m    180\u001b[0m     q_postfix \u001b[38;5;241m=\u001b[39m m\u001b[38;5;241m.\u001b[39mgroup(\u001b[38;5;241m3\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    181\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m q_values[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m q_values[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 182\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_do_execute_many(\n\u001b[0;32m    183\u001b[0m         q_prefix,\n\u001b[0;32m    184\u001b[0m         q_values,\n\u001b[0;32m    185\u001b[0m         q_postfix,\n\u001b[0;32m    186\u001b[0m         args,\n\u001b[0;32m    187\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_stmt_length,\n\u001b[0;32m    188\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_db()\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    189\u001b[0m     )\n\u001b[0;32m    191\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrowcount \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecute(query, arg) \u001b[38;5;28;01mfor\u001b[39;00m arg \u001b[38;5;129;01min\u001b[39;00m args)\n\u001b[0;32m    192\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrowcount\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\pymysql\\cursors.py:220\u001b[0m, in \u001b[0;36mCursor._do_execute_many\u001b[1;34m(self, prefix, values, postfix, args, max_stmt_length, encoding)\u001b[0m\n\u001b[0;32m    218\u001b[0m         sql \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    219\u001b[0m     sql \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m v\n\u001b[1;32m--> 220\u001b[0m rows \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecute(sql \u001b[38;5;241m+\u001b[39m postfix)\n\u001b[0;32m    221\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrowcount \u001b[38;5;241m=\u001b[39m rows\n\u001b[0;32m    222\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m rows\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\pymysql\\cursors.py:153\u001b[0m, in \u001b[0;36mCursor.execute\u001b[1;34m(self, query, args)\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m    151\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmogrify(query, args)\n\u001b[1;32m--> 153\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_query(query)\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_executed \u001b[38;5;241m=\u001b[39m query\n\u001b[0;32m    155\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\pymysql\\cursors.py:322\u001b[0m, in \u001b[0;36mCursor._query\u001b[1;34m(self, q)\u001b[0m\n\u001b[0;32m    320\u001b[0m conn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_db()\n\u001b[0;32m    321\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_clear_result()\n\u001b[1;32m--> 322\u001b[0m conn\u001b[38;5;241m.\u001b[39mquery(q)\n\u001b[0;32m    323\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_do_get_result()\n\u001b[0;32m    324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrowcount\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\pymysql\\connections.py:575\u001b[0m, in \u001b[0;36mConnection.query\u001b[1;34m(self, sql, unbuffered)\u001b[0m\n\u001b[0;32m    573\u001b[0m     sql \u001b[38;5;241m=\u001b[39m sql\u001b[38;5;241m.\u001b[39mencode(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoding, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msurrogateescape\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    574\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_execute_command(COMMAND\u001b[38;5;241m.\u001b[39mCOM_QUERY, sql)\n\u001b[1;32m--> 575\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_affected_rows \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read_query_result(unbuffered\u001b[38;5;241m=\u001b[39munbuffered)\n\u001b[0;32m    576\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_affected_rows\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\pymysql\\connections.py:826\u001b[0m, in \u001b[0;36mConnection._read_query_result\u001b[1;34m(self, unbuffered)\u001b[0m\n\u001b[0;32m    824\u001b[0m     result\u001b[38;5;241m.\u001b[39minit_unbuffered_query()\n\u001b[0;32m    825\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 826\u001b[0m     result\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m    827\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result \u001b[38;5;241m=\u001b[39m result\n\u001b[0;32m    828\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result\u001b[38;5;241m.\u001b[39mserver_status \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\pymysql\\connections.py:1203\u001b[0m, in \u001b[0;36mMySQLResult.read\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1201\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mread\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m   1202\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1203\u001b[0m         first_packet \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconnection\u001b[38;5;241m.\u001b[39m_read_packet()\n\u001b[0;32m   1205\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m first_packet\u001b[38;5;241m.\u001b[39mis_ok_packet():\n\u001b[0;32m   1206\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read_ok_packet(first_packet)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\pymysql\\connections.py:782\u001b[0m, in \u001b[0;36mConnection._read_packet\u001b[1;34m(self, packet_type)\u001b[0m\n\u001b[0;32m    780\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\u001b[38;5;241m.\u001b[39munbuffered_active \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    781\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\u001b[38;5;241m.\u001b[39munbuffered_active \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m--> 782\u001b[0m     packet\u001b[38;5;241m.\u001b[39mraise_for_error()\n\u001b[0;32m    783\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m packet\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\pymysql\\protocol.py:219\u001b[0m, in \u001b[0;36mMysqlPacket.raise_for_error\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    217\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m DEBUG:\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merrno =\u001b[39m\u001b[38;5;124m\"\u001b[39m, errno)\n\u001b[1;32m--> 219\u001b[0m err\u001b[38;5;241m.\u001b[39mraise_mysql_exception(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\pymysql\\err.py:150\u001b[0m, in \u001b[0;36mraise_mysql_exception\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    148\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m errorclass \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    149\u001b[0m     errorclass \u001b[38;5;241m=\u001b[39m InternalError \u001b[38;5;28;01mif\u001b[39;00m errno \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1000\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m OperationalError\n\u001b[1;32m--> 150\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m errorclass(errno, errval)\n",
      "\u001b[1;31mIntegrityError\u001b[0m: (pymysql.err.IntegrityError) (1062, \"Duplicate entry '28-15' for key 'PRIMARY'\")\n[SQL: INSERT INTO order_product (order_id, product_id) VALUES (%(order_id)s, %(product_id)s)]\n[parameters: [{'order_id': 5, 'product_id': 17}, {'order_id': 7, 'product_id': 18}, {'order_id': 7, 'product_id': 11}, {'order_id': 8, 'product_id': 13}, {'order_id': 9, 'product_id': 17}, {'order_id': 9, 'product_id': 15}, {'order_id': 9, 'product_id': 19}, {'order_id': 10, 'product_id': 5}  ... displaying 10 of 52 total bound parameter sets ...  {'order_id': 33, 'product_id': 6}, {'order_id': 34, 'product_id': 11}]]\n(Background on this error at: https://sqlalche.me/e/20/gkpj)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 1) find orders without items\n",
    "missing_orders = pd.read_sql(\"\"\"\n",
    "SELECT o.id\n",
    "FROM `order` o\n",
    "LEFT JOIN order_item oi ON oi.order_ref_id = o.id\n",
    "WHERE oi.id IS NULL\n",
    "\"\"\", engine)\n",
    "\n",
    "print(\"Orders without items:\", len(missing_orders))\n",
    "\n",
    "if len(missing_orders) == 0:\n",
    "    print(\"✅ No fix needed.\")\n",
    "else:\n",
    "    # load products\n",
    "    products = pd.read_sql(\"SELECT id, price FROM product\", engine)\n",
    "    prod_ids = products[\"id\"].tolist()\n",
    "    price_map = dict(zip(products[\"id\"], products[\"price\"].astype(float)))\n",
    "\n",
    "    rng = np.random.default_rng(42)\n",
    "\n",
    "    # create items\n",
    "    rows_item = []\n",
    "    rows_order_product = []\n",
    "    rows_total = []\n",
    "\n",
    "    for oid in missing_orders[\"id\"].tolist():\n",
    "        k = int(rng.integers(1, 4))  # 1..3 products per order\n",
    "        picked = rng.choice(prod_ids, size=k, replace=False)\n",
    "\n",
    "        total = 0.0\n",
    "        for pid in picked:\n",
    "            qty = int(rng.integers(1, 4))  # 1..3 qty\n",
    "            unit_price = float(price_map[int(pid)])\n",
    "            total += unit_price * qty\n",
    "\n",
    "            rows_item.append({\n",
    "                \"order_ref_id\": int(oid),\n",
    "                \"product_id\": int(pid),\n",
    "                \"quantity\": qty,\n",
    "                \"unit_price\": f\"{unit_price:.2f}\",\n",
    "            })\n",
    "            rows_order_product.append({\n",
    "                \"order_id\": int(oid),\n",
    "                \"product_id\": int(pid),\n",
    "            })\n",
    "\n",
    "        rows_total.append({\n",
    "            \"id\": int(oid),\n",
    "            \"total_amount\": f\"{total:.2f}\"\n",
    "        })\n",
    "\n",
    "    df_items = pd.DataFrame(rows_item)\n",
    "    df_op = pd.DataFrame(rows_order_product)\n",
    "    df_total = pd.DataFrame(rows_total)\n",
    "\n",
    "    # 2) insert order_item\n",
    "    df_items.to_sql(\"order_item\", engine, if_exists=\"append\", index=False)\n",
    "\n",
    "    # 3) insert order_product (avoid duplicates just in case)\n",
    "    df_op.to_sql(\"order_product\", engine, if_exists=\"append\", index=False)\n",
    "\n",
    "    # 4) update order.total_amount\n",
    "    with engine.begin() as conn:\n",
    "        for r in rows_total:\n",
    "            conn.execute(\n",
    "                text(\"UPDATE `order` SET total_amount = :t WHERE id = :id\"),\n",
    "                {\"t\": r[\"total_amount\"], \"id\": r[\"id\"]}\n",
    "            )\n",
    "\n",
    "    print(\"✅ Fixed:\", len(missing_orders), \"orders by adding items + totals.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "16bf90be-09a8-49fb-b6c8-67538821f3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "040ad043-2e27-4873-93fd-6a62fad361b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Orders without items: 0\n",
      "✅ No fix needed.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 1) find orders without items\n",
    "missing_orders = pd.read_sql(\"\"\"\n",
    "SELECT o.id\n",
    "FROM `order` o\n",
    "LEFT JOIN order_item oi ON oi.order_ref_id = o.id\n",
    "WHERE oi.id IS NULL\n",
    "\"\"\", engine)\n",
    "\n",
    "print(\"Orders without items:\", len(missing_orders))\n",
    "\n",
    "if len(missing_orders) == 0:\n",
    "    print(\"✅ No fix needed.\")\n",
    "else:\n",
    "    # load products\n",
    "    products = pd.read_sql(\"SELECT id, price FROM product\", engine)\n",
    "    prod_ids = products[\"id\"].tolist()\n",
    "    price_map = dict(zip(products[\"id\"], products[\"price\"].astype(float)))\n",
    "\n",
    "    rng = np.random.default_rng(42)\n",
    "\n",
    "    # create items\n",
    "    rows_item = []\n",
    "    rows_order_product = []\n",
    "    rows_total = []\n",
    "\n",
    "    for oid in missing_orders[\"id\"].tolist():\n",
    "        k = int(rng.integers(1, 4))  # 1..3 products per order\n",
    "        picked = rng.choice(prod_ids, size=k, replace=False)\n",
    "\n",
    "        total = 0.0\n",
    "        for pid in picked:\n",
    "            qty = int(rng.integers(1, 4))  # 1..3 qty\n",
    "            unit_price = float(price_map[int(pid)])\n",
    "            total += unit_price * qty\n",
    "\n",
    "            rows_item.append({\n",
    "                \"order_ref_id\": int(oid),\n",
    "                \"product_id\": int(pid),\n",
    "                \"quantity\": qty,\n",
    "                \"unit_price\": f\"{unit_price:.2f}\",\n",
    "            })\n",
    "            rows_order_product.append({\n",
    "                \"order_id\": int(oid),\n",
    "                \"product_id\": int(pid),\n",
    "            })\n",
    "\n",
    "        rows_total.append({\n",
    "            \"id\": int(oid),\n",
    "            \"total_amount\": f\"{total:.2f}\"\n",
    "        })\n",
    "\n",
    "    df_items = pd.DataFrame(rows_item)\n",
    "    df_op = pd.DataFrame(rows_order_product)\n",
    "    df_total = pd.DataFrame(rows_total)\n",
    "\n",
    "    # 2) insert order_item\n",
    "    df_items.to_sql(\"order_item\", engine, if_exists=\"append\", index=False)\n",
    "\n",
    "    # 3) insert order_product (avoid duplicates just in case)\n",
    "    df_op.to_sql(\"order_product\", engine, if_exists=\"append\", index=False)\n",
    "\n",
    "    # 4) update order.total_amount\n",
    "    with engine.begin() as conn:\n",
    "        for r in rows_total:\n",
    "            conn.execute(\n",
    "                text(\"UPDATE `order` SET total_amount = :t WHERE id = :id\"),\n",
    "                {\"t\": r[\"total_amount\"], \"id\": r[\"id\"]}\n",
    "            )\n",
    "\n",
    "    print(\"✅ Fixed:\", len(missing_orders), \"orders by adding items + totals.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e081f60-e4f7-4ba2-a0e0-df207759f077",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
